{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b12b29",
   "metadata": {},
   "source": [
    "# Recent  Approach : AthletePose3D - 3D Human Pose Estimation\n",
    "Based on: Yeung et al. (2025) - AthletePose3D Dataset Paper\n",
    "\n",
    "Implementation of methods from the paper:\n",
    "- 2D Pose Detection (HRNet/ViTPose approach)\n",
    "- 3D Pose Lifting (MotionAGFormer/TCPFormer)\n",
    "- Kinematic Validation (Joint angles & velocities)\n",
    "- Metrics: MPJPE, P-MPJPE, PDJ\n",
    "\n",
    "Data  set : AthletePose3D: A Benchmark Dataset for 3D Human Pose Estimation and Kinematic Validation in Athletic Movements\n",
    "Dataset Overview (Table 1 & 2 from Paper)\n",
    "\n",
    "| Characteristic | Details |\n",
    "|---------------|---------|\n",
    "| **Total Frames** | 1.3 million frames |\n",
    "| **Postures** | 165,000 individual postures |\n",
    "| **Sports** | 3 categories, 12 motion types |\n",
    "| **Athletes** | 8 athletes (amateur to professional) |\n",
    "| **Keypoints** | 55/86 keypoints (varies by sport) |\n",
    "| **Cameras** | 4-12 high-speed synchronized cameras |\n",
    "| **Resolution** | 1920√ó1080 |\n",
    "\n",
    " Three Sport Categories :\n",
    "[alt text](datset.jpg)\n",
    "\n",
    "\n",
    " 1. Running (Lab Environment)\n",
    " 2. Track & Field (Lab Environment)\n",
    " 3. Figure Skating (Ice Rink)\n",
    "\n",
    "we choose some running data  videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 1. Install Required Libraries \n",
    "What this does: Installs libraries mentioned in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03135d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" INSTALLING LIBRARIES (Paper Technologies Only)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Paper mentions these frameworks\n",
    "packages = [\n",
    "    'opencv-python',      # Video processing\n",
    "    'numpy',              # Numerical computations\n",
    "    'matplotlib',         # Visualization\n",
    "    'scipy',              # Butterworth filter (Section 3.3)\n",
    "    'torch',              # Deep learning framework\n",
    "    'torchvision',        # Vision models\n",
    "    'mediapipe',          # For demo (lightweight alternative)\n",
    "    'pillow',             # Image processing\n",
    "]\n",
    "\n",
    "print(\"\\nInstalling packages...\")\n",
    "for pkg in packages:\n",
    "    print(f\"  Installing {pkg}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "print(\"\\n‚úì Installation complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7bab0",
   "metadata": {},
   "source": [
    "# 2. Import Libraries and Setup\n",
    " What this does: Imports all required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.spatial.transform import Rotation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  AthletePose3D Implementation\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nPaper Information:\")\n",
    "print(\"  Title: AthletePose3D\")\n",
    "print(\"  Authors: Yeung et al. (2025)\")\n",
    "print(\"  Focus: 3D pose estimation for athletic movements\")\n",
    "print(\"  Dataset: 1.3M frames, 165K postures, 12 sports\")\n",
    "print(\"\\nKey Technologies (from paper):\")\n",
    "print(\"  ‚Ä¢ 2D Models: HRNet, ViTPose, MogaNet (best: PDJ 95.7)\")\n",
    "print(\"  ‚Ä¢ 3D Models: MotionAGFormer, TCPFormer (best: MPJPE 98.26mm)\")\n",
    "print(\"  ‚Ä¢ Metrics: MPJPE, P-MPJPE, PDJ\")\n",
    "print(\"  ‚Ä¢ Kinematic: 4th-order Butterworth filter @ 8Hz\")\n",
    "print(\"  ‚Ä¢ Input: 81 frames per sequence\")\n",
    "print(\"  ‚Ä¢ Resolution: 1920√ó1080 @ 60/120 FPS\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c29f5c6",
   "metadata": {},
   "source": [
    "# 3. Load  Running Videos\n",
    "What this does: Loads your 10-12 running videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332425fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FOLDER = \"New_Paper\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" LOADING YOUR RUNNING VIDEOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if folder exists\n",
    "if not os.path.exists(VIDEO_FOLDER):\n",
    "    print(f\"\\n‚ùå ERROR: Folder '{VIDEO_FOLDER}' not found!\")\n",
    "    print(\"Please create the folder and add your running videos.\")\n",
    "    print(\"\\nExpected structure:\")\n",
    "    print(\"  new_paper/\")\n",
    "    print(\"    ‚îú‚îÄ‚îÄ run1.mp4\")\n",
    "    print(\"    ‚îú‚îÄ‚îÄ run2.mp4\")\n",
    "    print(\"    ‚îî‚îÄ‚îÄ ...\")\n",
    "else:\n",
    "    # Find all video files\n",
    "    video_files = []\n",
    "    for ext in ['*.mp4', '*.avi', '*.mov', '*.MP4', '*.AVI', '*.MOV']:\n",
    "        video_files.extend(Path(VIDEO_FOLDER).glob(ext))\n",
    "    \n",
    "    video_files = [str(f) for f in video_files]\n",
    "    \n",
    "    print(f\"\\n‚úì Found {len(video_files)} videos:\")\n",
    "    for i, vf in enumerate(video_files, 1):\n",
    "        # Get video info\n",
    "        cap = cv2.VideoCapture(vf)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        duration = frame_count / fps if fps > 0 else 0\n",
    "        cap.release()\n",
    "        \n",
    "        print(f\"  {i}. {os.path.basename(vf)}\")\n",
    "        print(f\"     Resolution: {width}x{height}, FPS: {fps:.1f}, \"\n",
    "              f\"Frames: {frame_count}, Duration: {duration:.1f}s\")\n",
    "    \n",
    "    print(f\"\\nPaper specifications:\")\n",
    "    print(f\"  ‚Ä¢ Running: 120 FPS (your videos may vary)\")\n",
    "    print(f\"  ‚Ä¢ Resolution: 1920√ó1080 (paper standard)\")\n",
    "    print(f\"  ‚Ä¢ Athletes: Inter-university level\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511dca57",
   "metadata": {},
   "source": [
    "# 4.Load and Process Single Video\n",
    " What this does: Loads one video for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a6da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(video_files) > 0:\n",
    "    # Select first video\n",
    "    selected_video = video_files[0]\n",
    "    print(f\"\\nüìπ Processing: {os.path.basename(selected_video)}\")\n",
    "    \n",
    "    # Load video frames\n",
    "    cap = cv2.VideoCapture(selected_video)\n",
    "    frames = []\n",
    "    \n",
    "    print(\"Loading frames...\")\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"  Loaded {frame_count} frames...\", end='\\r')\n",
    "    \n",
    "    cap.release()\n",
    "    frames = np.array(frames)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    print(f\"\\n‚úì Loaded {len(frames)} frames\")\n",
    "    print(f\"  Shape: {frames.shape}\")\n",
    "    print(f\"  FPS: {fps:.1f}\")\n",
    "    print(f\"  Duration: {len(frames)/fps:.2f}s\")\n",
    "    \n",
    "    # Display sample frames\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    sample_indices = [0, len(frames)//2, len(frames)-1]\n",
    "    \n",
    "    for ax, idx in zip(axes, sample_indices):\n",
    "        ax.imshow(frames[idx])\n",
    "        ax.set_title(f\"Frame {idx}\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Sample Frames from Your Running Video\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No videos found. Please add videos to new_paper/ folder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0cfa2",
   "metadata": {},
   "source": [
    "# 5. nitialize 2D Pose Detector (Paper Models)\n",
    " What this does: Sets up 2D pose estimation\n",
    " Paper Section 3.2: HRNet, ViTPose, MogaNet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
